{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "XOR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcruzrui/deep-learning/blob/master/XOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCW3ADKvpKAX"
      },
      "source": [
        "# XOR con Keras\n",
        "## Deep Learning\n",
        "\n",
        "\n",
        "\n",
        "> Brandon Alain Cruz Ruiz\n",
        "\n",
        "> Oscar Allan Ruiz Toledo\n",
        "\n"
      ],
      "id": "GCW3ADKvpKAX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r95ZWyJSu2EI"
      },
      "source": [
        "Inicializamos nuestras entradas y nuestras salidas que servirán para el modelo."
      ],
      "id": "r95ZWyJSu2EI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upset-edwards"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
        "outputs = np.array([[0],[1],[1],[0]], \"float32\")"
      ],
      "id": "upset-edwards",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1LIZbguvKB3"
      },
      "source": [
        "Utilizaremos keras para la creación del modelo, en este primer ejemplo utilizaremos una red oculta de 16 nodos con la función de activación Relu para la capa oculta y Sigmoid para la capa de salida."
      ],
      "id": "n1LIZbguvKB3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FM8ABOwutd-"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(16, input_dim=2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "id": "3FM8ABOwutd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBpQSgY2vLro"
      },
      "source": [
        "Pensabamos utilizar funciones de pérdida y optimizadores \"externos\" como los ejercicios vistos en clase, pero fue más sencillo agregarlos directamente al modelo con las funciones predefinidas de keras. Utilizamos la función de pérdida de [entropía cruzada binaria](https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class), pues de acuerdo al [artículo](hthttps://medium.com/analytics-vidhya/understanding-basics-of-deep-learning-by-solving-xor-problem-cb3ff6a18a06tps://) leído esta función de pérdida es la mas adecuada para este ejemplo, y el [optimizador de gradiente descendiente](https://keras.io/api/optimizers/sgd/)."
      ],
      "id": "kBpQSgY2vLro"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZj4D7ClauQ",
        "outputId": "ae587091-4cf2-425c-b47b-d9a2362d5769"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['binary_accuracy'])"
      ],
      "id": "OZZj4D7ClauQ",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f88197be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Ihe-MAwQvI"
      },
      "source": [
        "Finalmente entrenamos el modelo. En este caso fue un poco de prueba y error para determinar el número adecuado de epochs para poder optener una precisión adecuada para el modelo. En este caso utilizamos 480 epochs, pero viendo los resultados, más o menos obtenemos los resultados esperados aproximadamente a partir de la epoch 460."
      ],
      "id": "I_Ihe-MAwQvI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ZiGrvwuy1S",
        "outputId": "412ffecc-5664-4c9b-b16a-4751fd92965e"
      },
      "source": [
        "model.fit(inputs, outputs, verbose=0, epochs=480)"
      ],
      "id": "M_ZiGrvwuy1S",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f82c9dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOXq025_wSln"
      },
      "source": [
        "Y al momento de realizar una predicción, logramos los resultados esperados. \n",
        "\n",
        "Nota: Al aumentar las epochs a 500, el último valor que debería ser 0 se volvía 1."
      ],
      "id": "EOXq025_wSln"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqW94R45lgBG",
        "outputId": "263212ff-b9eb-4ca0-fc2c-d89c7dfb47e2"
      },
      "source": [
        "print(model.predict(inputs).round())"
      ],
      "id": "jqW94R45lgBG",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX6z1vTgwZmA"
      },
      "source": [
        "Realizamos un segundo modelo con una segunda capa oculta igual de 16 nodos para observar si existían mejoras en el número de epochs que se realizan."
      ],
      "id": "WX6z1vTgwZmA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkxxgmoGp-7i",
        "outputId": "009b19da-ea5c-4152-9ceb-1de654d6d7c5"
      },
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(16, input_dim=2, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "model2.fit(inputs, outputs, verbose=0, epochs=300)"
      ],
      "id": "XkxxgmoGp-7i",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f82c00c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eVboUs7w_ab"
      },
      "source": [
        "Agregando una segunda capa oculta, observamos mejoría evidente. El número de epochs necesarios para alcanzar una precisión de 1 es aproximadamente a partir de la epoch número 230."
      ],
      "id": "1eVboUs7w_ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkdMrCgKqoma",
        "outputId": "22fcda82-7d5e-46f1-b065-325cee5021f9"
      },
      "source": [
        "print(model2.predict(inputs).round())"
      ],
      "id": "fkdMrCgKqoma",
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6f8c5c60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNGX_5qbxWWU"
      },
      "source": [
        "Estos fueron los sitios que nos ayudaron a crear esta red neuronal utilizando keras:\n",
        "\n",
        "*   Burgdorf, G. (2016). *Understanding XOR with Keras and TensorFlow*. Thoughtram. https://blog.thoughtram.io/machine-learning/2016/11/02/understanding-XOR-with-keras-and-tensorlow.html\n",
        "*   Pal, L. (2019). *Understanding Basics of Deep Learning by solving XOR problem*. Medium. https://medium.com/analytics-vidhya/understanding-basics-of-deep-learning-by-solving-xor-problem-cb3ff6a18a06"
      ],
      "id": "CNGX_5qbxWWU"
    }
  ]
}